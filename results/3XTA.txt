sbc-bench v0.9.6 Radxa ROCK 5A (Mon, 16 May 2022 07:32:12 +0000)

Distributor ID:	Debian
Description:	Debian GNU/Linux 11 (bullseye)
Release:	11
Codename:	bullseye

/usr/bin/gcc (Debian 10.2.1-6) 10.2.1 20210110

Uptime: 07:32:13 up 2 days, 21:36,  1 user,  load average: 1.22, 0.62, 0.40

Linux 5.10.66-rockchip-5.10 (radxa) 	05/16/22 	_aarch64_	(8 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.05    0.00    0.98    0.01    0.00   98.96

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
mmcblk0           0.61         0.65         8.00       119.23     163669    2004086   29877055

               total        used        free      shared  buff/cache   available
Mem:           3.7Gi       205Mi       3.3Gi       9.0Mi       109Mi       3.4Gi
Swap:             0B          0B          0B

##########################################################################

Checking cpufreq OPP for cpu0-cpu3 (Cortex-A55):

Cpufreq OPP: 1800    Measured: 1790 (1786.899/1783.937/1782.262)
Cpufreq OPP: 1608    Measured: 1610 (1609.681/1605.278/1604.540)
Cpufreq OPP: 1416    Measured: 1420 (1416.350/1414.999/1413.837)
Cpufreq OPP: 1200    Measured: 1225 (1223.636/1220.037/1215.044)
Cpufreq OPP: 1008    Measured: 1000 (997.591/996.484/993.501)
Cpufreq OPP:  816    Measured:  800 (797.207/794.468/787.531)
Cpufreq OPP:  600    Measured:  590 (589.856/589.632/586.370)
Cpufreq OPP:  408    Measured:  395 (394.320/390.544/388.848)

Checking cpufreq OPP for cpu4-cpu5 (Cortex-A76):

Cpufreq OPP: 2400    Measured: 2290 (2287.694/2287.565/2287.383)
Cpufreq OPP: 2208    Measured: 2155 (2154.324/2154.255/2154.255)
Cpufreq OPP: 2016    Measured: 1990 (1989.285/1989.163/1989.089)
Cpufreq OPP: 1800    Measured: 1825 (1821.461/1821.420/1821.379)
Cpufreq OPP: 1608    Measured: 1625 (1624.552/1624.421/1624.388)
Cpufreq OPP: 1416    Measured: 1430 (1427.845/1427.593/1427.466)
Cpufreq OPP: 1200    Measured: 1205 (1203.423/1203.128/1202.890)
Cpufreq OPP: 1008    Measured:  985 (980.221/980.104/980.011)
Cpufreq OPP:  816    Measured:  795 (790.686/790.573/790.440)
Cpufreq OPP:  600    Measured:  595 (592.884/592.705/592.658)
Cpufreq OPP:  408    Measured:  395 (394.872/394.840/394.674)

Checking cpufreq OPP for cpu6-cpu7 (Cortex-A76):

Cpufreq OPP: 2400    Measured: 2295 (2291.514/2291.123/2291.123)
Cpufreq OPP: 2208    Measured: 2135 (2134.315/2134.067/2133.931)
Cpufreq OPP: 2016    Measured: 1970 (1965.976/1965.905/1965.857)
Cpufreq OPP: 1800    Measured: 1795 (1794.707/1794.648/1794.528)
Cpufreq OPP: 1608    Measured: 1595 (1594.594/1594.436/1594.338)
Cpufreq OPP: 1416    Measured: 1400 (1399.419/1399.313/1399.298)
Cpufreq OPP: 1200    Measured: 1210 (1209.071/1209.014/1208.915)
Cpufreq OPP: 1008    Measured:  990 (987.412/987.235/987.211)
Cpufreq OPP:  816    Measured:  795 (794.620/794.458/794.372)
Cpufreq OPP:  600    Measured:  595 (592.891/592.831/592.791)
Cpufreq OPP:  408    Measured:  395 (394.955/394.900/394.872)

##########################################################################

Hardware sensors:

npu_thermal-virtual-0
temp1:        +62.8 C  

center_thermal-virtual-0
temp1:        +63.8 C  

bigcore1_thermal-virtual-0
temp1:        +63.8 C  

soc_thermal-virtual-0
temp1:        +63.8 C  (crit = +115.0 C)

gpu_thermal-virtual-0
temp1:        +62.8 C  

littlecore_thermal-virtual-0
temp1:        +63.8 C  

bigcore0_thermal-virtual-0
temp1:        +63.8 C  

##########################################################################

Executing benchmark on cpu0 (Cortex-A55):

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   3047.6 MB/s (0.5%)
 C copy backwards (32 byte blocks)                    :   3032.6 MB/s (2.9%)
 C copy backwards (64 byte blocks)                    :   2873.9 MB/s (1.0%)
 C copy                                               :   5412.3 MB/s (2.5%)
 C copy prefetched (32 bytes step)                    :   2228.3 MB/s (0.3%)
 C copy prefetched (64 bytes step)                    :   5472.7 MB/s (0.4%)
 C 2-pass copy                                        :   2598.0 MB/s (0.4%)
 C 2-pass copy prefetched (32 bytes step)             :   1809.7 MB/s (0.6%)
 C 2-pass copy prefetched (64 bytes step)             :   2800.4 MB/s (0.3%)
 C fill                                               :  12274.1 MB/s (0.3%)
 C fill (shuffle within 16 byte blocks)               :  12268.4 MB/s (0.3%)
 C fill (shuffle within 32 byte blocks)               :  12267.6 MB/s (1.8%)
 C fill (shuffle within 64 byte blocks)               :  11563.0 MB/s (0.4%)
 ---
 standard memcpy                                      :   5705.7 MB/s (0.5%)
 standard memset                                      :  21297.8 MB/s (0.3%)
 ---
 NEON LDP/STP copy                                    :   5025.3 MB/s (0.3%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   1799.2 MB/s
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   3315.1 MB/s (2.3%)
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   2418.3 MB/s (0.5%)
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   4823.6 MB/s (1.6%)
 NEON LD1/ST1 copy                                    :   4861.5 MB/s (0.3%)
 NEON STP fill                                        :  21217.7 MB/s (0.3%)
 NEON STNP fill                                       :  13966.3 MB/s (1.4%)
 ARM LDP/STP copy                                     :   4786.7 MB/s (0.2%)
 ARM STP fill                                         :  21162.4 MB/s (2.0%)
 ARM STNP fill                                        :  13925.3 MB/s (3.0%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :    330.1 MB/s (0.3%)
 NEON LDP/STP 2-pass copy (from framebuffer)          :    311.9 MB/s (0.2%)
 NEON LD1/ST1 copy (from framebuffer)                 :     86.8 MB/s (1.4%)
 NEON LD1/ST1 2-pass copy (from framebuffer)          :     86.4 MB/s (1.4%)
 ARM LDP/STP copy (from framebuffer)                  :    173.0 MB/s (0.3%)
 ARM LDP/STP 2-pass copy (from framebuffer)           :    167.9 MB/s (0.2%)

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.1 ns          /     0.2 ns 
     32768 :    0.8 ns          /     1.4 ns 
     65536 :    1.6 ns          /     3.2 ns 
    131072 :    3.5 ns          /     5.8 ns 
    262144 :    8.2 ns          /    12.1 ns 
    524288 :   11.8 ns          /    15.4 ns 
   1048576 :   13.8 ns          /    16.4 ns 
   2097152 :   15.6 ns          /    17.2 ns 
   4194304 :   44.9 ns          /    66.8 ns 
   8388608 :   87.2 ns          /   121.8 ns 
  16777216 :  109.8 ns          /   141.3 ns 
  33554432 :  123.2 ns          /   151.7 ns 
  67108864 :  132.0 ns          /   161.4 ns 

Executing benchmark on cpu4 (Cortex-A76):

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   9875.4 MB/s
 C copy backwards (32 byte blocks)                    :   9801.0 MB/s
 C copy backwards (64 byte blocks)                    :   9800.0 MB/s
 C copy                                               :  10063.3 MB/s
 C copy prefetched (32 bytes step)                    :  10252.3 MB/s
 C copy prefetched (64 bytes step)                    :  10296.3 MB/s (0.1%)
 C 2-pass copy                                        :   4827.1 MB/s
 C 2-pass copy prefetched (32 bytes step)             :   7186.0 MB/s
 C 2-pass copy prefetched (64 bytes step)             :   7597.8 MB/s
 C fill                                               :  24397.0 MB/s (9.6%)
 C fill (shuffle within 16 byte blocks)               :  19226.1 MB/s (5.5%)
 C fill (shuffle within 32 byte blocks)               :  16959.0 MB/s (5.2%)
 C fill (shuffle within 64 byte blocks)               :  18663.5 MB/s (8.5%)
 ---
 standard memcpy                                      :   7663.5 MB/s (5.5%)
 standard memset                                      :  15099.1 MB/s (3.4%)
 ---
 NEON LDP/STP copy                                    :   6999.4 MB/s (5.5%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   6659.4 MB/s (7.0%)
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   6761.7 MB/s (8.0%)
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   6355.1 MB/s (6.1%)
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   6930.8 MB/s (8.9%)
 NEON LD1/ST1 copy                                    :   5849.0 MB/s (4.0%)
 NEON STP fill                                        :  13526.9 MB/s (6.5%)
 NEON STNP fill                                       :  13958.1 MB/s (7.2%)
 ARM LDP/STP copy                                     :   6265.9 MB/s (7.2%)
 ARM STP fill                                         :  12702.6 MB/s (13.2%)
 ARM STNP fill                                        :  14798.5 MB/s (13.7%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :   1737.1 MB/s (4.3%)
 NEON LDP/STP 2-pass copy (from framebuffer)          :   1553.0 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :   1736.2 MB/s
 NEON LD1/ST1 2-pass copy (from framebuffer)          :   1555.9 MB/s (0.8%)
 ARM LDP/STP copy (from framebuffer)                  :   1705.3 MB/s
 ARM LDP/STP 2-pass copy (from framebuffer)           :   1554.6 MB/s

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    0.0 ns          /     0.0 ns 
    131072 :    1.1 ns          /     1.5 ns 
    262144 :    2.2 ns          /     2.9 ns 
    524288 :    4.1 ns          /     5.3 ns 
   1048576 :   10.1 ns          /    13.3 ns 
   2097152 :   13.8 ns          /    16.0 ns 
   4194304 :   38.4 ns          /    56.9 ns 
   8388608 :   81.2 ns          /   112.6 ns 
  16777216 :  105.5 ns          /   133.4 ns 
  33554432 :  118.3 ns          /   141.7 ns 
  67108864 :  125.7 ns          /   146.2 ns 

Executing benchmark on cpu6 (Cortex-A76):

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   9871.0 MB/s
 C copy backwards (32 byte blocks)                    :   9441.1 MB/s (7.2%)
 C copy backwards (64 byte blocks)                    :   7405.5 MB/s (5.5%)
 C copy                                               :   6986.6 MB/s (6.7%)
 C copy prefetched (32 bytes step)                    :   6665.6 MB/s (6.5%)
 C copy prefetched (64 bytes step)                    :   5791.0 MB/s (5.6%)
 C 2-pass copy                                        :   4058.9 MB/s (3.8%)
 C 2-pass copy prefetched (32 bytes step)             :   5082.2 MB/s (7.0%)
 C 2-pass copy prefetched (64 bytes step)             :   5192.6 MB/s (4.2%)
 C fill                                               :  13812.4 MB/s (12.5%)
 C fill (shuffle within 16 byte blocks)               :  12793.1 MB/s (10.3%)
 C fill (shuffle within 32 byte blocks)               :  12262.8 MB/s (11.2%)
 C fill (shuffle within 64 byte blocks)               :  10568.3 MB/s (7.7%)
 ---
 standard memcpy                                      :   5977.6 MB/s (7.6%)
 standard memset                                      :  14790.3 MB/s (7.4%)
 ---
 NEON LDP/STP copy                                    :   5738.5 MB/s (8.0%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   4937.3 MB/s (2.6%)
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   4628.4 MB/s (0.3%)
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   4487.5 MB/s
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   4480.9 MB/s (0.4%)
 NEON LD1/ST1 copy                                    :   4511.6 MB/s (2.7%)
 NEON STP fill                                        :  11294.3 MB/s (12.0%)
 NEON STNP fill                                       :  10833.7 MB/s (11.3%)
 ARM LDP/STP copy                                     :   5144.2 MB/s (5.7%)
 ARM STP fill                                         :  11239.8 MB/s (15.7%)
 ARM STNP fill                                        :  10233.2 MB/s (4.9%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :   1737.3 MB/s (6.2%)
 NEON LDP/STP 2-pass copy (from framebuffer)          :   1551.8 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :   1736.5 MB/s
 NEON LD1/ST1 2-pass copy (from framebuffer)          :   1554.8 MB/s
 ARM LDP/STP copy (from framebuffer)                  :   1706.3 MB/s
 ARM LDP/STP 2-pass copy (from framebuffer)           :   1554.3 MB/s

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    0.0 ns          /     0.0 ns 
    131072 :    1.1 ns          /     1.5 ns 
    262144 :    2.1 ns          /     2.8 ns 
    524288 :    4.2 ns          /     5.4 ns 
   1048576 :    9.3 ns          /    12.5 ns 
   2097152 :   13.7 ns          /    16.1 ns 
   4194304 :   37.7 ns          /    57.1 ns 
   8388608 :   78.9 ns          /   109.9 ns 
  16777216 :  104.2 ns          /   131.9 ns 
  33554432 :  117.3 ns          /   140.7 ns 
  67108864 :  125.1 ns          /   145.6 ns 

##########################################################################

Executing ramlat on cpu0 (Cortex-A55), results in ns:

       size:  1x32  2x32  1x64  2x64 1xPTR 2xPTR 4xPTR
         4k: 5.204 7.013 4.215 7.006 2.989 3.627 7.008 
         8k: 5.220 7.010 4.156 7.001 2.998 3.683 7.012 
        16k: 5.210 7.005 4.162 7.006 2.990 3.626 7.007 
        32k: 5.315 7.248 4.220 7.105 3.027 3.688 7.164 
        64k: 12.51 15.12 11.53 15.10 11.24 14.31 19.92 
       128k: 15.67 19.16 14.39 19.19 14.20 18.58 31.11 
       256k: 19.71 32.39 18.65 32.00 18.67 30.34 55.01 
       512k: 22.03 38.05 20.82 37.90 19.38 34.29 65.80 
      1024k: 21.72 38.52 20.28 38.63 19.01 34.50 71.40 
      2048k: 23.82 42.30 22.15 42.60 21.00 38.99 78.92 
      4096k: 65.47 111.5 73.79 116.4 60.41 111.8 233.0 
      8192k: 109.8 207.9 107.7 190.2 107.7 196.6 397.3 
     16384k: 132.0 216.1 128.6 223.2 130.6 237.2 496.5 

Executing ramlat on cpu4 (Cortex-A76), results in ns:

       size:  1x32  2x32  1x64  2x64 1xPTR 2xPTR 4xPTR
         4k: 4.742 5.083 4.741 5.105 4.245 4.840 4.256 
         8k: 4.745 5.082 4.757 5.104 4.244 4.840 4.259 
        16k: 4.744 5.082 4.758 5.105 4.245 4.841 4.259 
        32k: 4.747 5.082 4.753 5.105 4.246 4.840 4.259 
        64k: 4.771 5.108 4.775 5.151 4.261 4.673 4.361 
       128k: 7.455 8.958 7.459 8.865 7.284 7.811 8.914 
       256k: 9.260 9.892 9.302 9.934 8.643 9.629 10.04 
       512k: 12.93 14.31 12.79 14.32 11.96 14.08 14.82 
      1024k: 20.59 22.06 20.71 21.87 20.00 21.94 24.24 
      2048k: 24.50 27.27 24.51 27.26 23.87 27.06 29.72 
      4096k: 58.07 65.92 57.86 63.44 57.93 66.06 57.98 
      8192k: 107.2 105.9 106.1 105.2 106.3 112.2 95.97 
     16384k: 126.8 123.5 126.3 123.6 127.5 133.2 120.0 

Executing ramlat on cpu6 (Cortex-A76), results in ns:

       size:  1x32  2x32  1x64  2x64 1xPTR 2xPTR 4xPTR
         4k: 4.748 5.084 4.754 5.104 4.244 4.840 4.255 
         8k: 4.742 5.081 4.757 5.103 4.243 4.838 4.257 
        16k: 4.755 5.079 4.752 5.102 4.243 4.838 4.257 
        32k: 4.757 5.078 4.754 5.103 4.242 4.829 4.256 
        64k: 4.765 5.102 4.766 5.124 4.257 4.634 4.307 
       128k: 7.432 8.877 7.433 8.530 7.274 7.823 8.895 
       256k: 9.268 9.884 9.263 9.768 8.623 9.535 9.967 
       512k: 10.86 11.96 10.92 11.89 10.16 11.62 12.18 
      1024k: 19.88 22.00 19.93 21.90 19.18 21.52 23.89 
      2048k: 21.73 23.58 21.59 23.49 20.98 23.32 26.50 
      4096k: 57.15 65.94 56.81 64.94 55.88 64.91 57.80 
      8192k: 107.7 106.1 106.0 105.4 105.5 117.8 96.28 
     16384k: 127.8 124.1 126.3 123.4 127.1 132.9 118.2 

##########################################################################

Executing benchmark on each cluster individually

OpenSSL 1.1.1n, built on 15 Mar 2022
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes  16384 bytes
aes-128-cbc     161341.40k   473277.48k   919989.76k  1210122.24k  1331533.14k  1320828.93k
aes-128-cbc     630418.03k  1292907.88k  1649800.36k  1759838.21k  1803728.21k  1809864.02k
aes-128-cbc     632099.01k  1290229.61k  1650414.76k  1761060.86k  1804815.02k  1810890.75k
aes-192-cbc     152499.20k   418008.15k   722455.38k   898528.26k   969640.62k   975394.13k
aes-192-cbc     591653.81k  1128214.06k  1394152.02k  1452137.81k  1505274.54k  1509119.32k
aes-192-cbc     593095.15k  1129897.24k  1393886.55k  1452646.06k  1505695.06k  1509599.91k
aes-256-cbc     142105.70k   372597.93k   637916.93k   778358.10k   827547.65k   830636.03k
aes-256-cbc     590740.81k  1002275.67k  1208003.07k  1267317.08k  1291892.05k  1294559.91k
aes-256-cbc     591328.10k  1003636.82k  1208530.01k  1267129.69k  1291973.97k  1294729.22k

##########################################################################

Executing benchmark single-threaded on cpu0 (Cortex-A55)

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: 64000000 - - - - - - - 2048000000

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:    435 MB,  # Benchmark threads:      1

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       1329   100   1293   1293  |      21357   100   1824   1824
23:       1248   100   1272   1272  |      20275   100   1755   1755
24:       1219   100   1311   1311  |      20734   100   1820   1820
25:       1165   100   1331   1331  |      20210   100   1799   1799
----------------------------------  | ------------------------------
Avr:             100   1302   1302  |              100   1800   1799
Tot:             100   1551   1551

Executing benchmark single-threaded on cpu4 (Cortex-A76)

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - - - - - - - -

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:    435 MB,  # Benchmark threads:      1

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       2986   100   2906   2905  |      37334   100   3188   3188
23:       2853   100   2908   2908  |      36643   100   3172   3172
24:       2729   100   2935   2934  |      36015   100   3162   3162
25:       2608   100   2978   2978  |      35328   100   3145   3144
----------------------------------  | ------------------------------
Avr:             100   2932   2931  |              100   3167   3166
Tot:             100   3049   3049

Executing benchmark single-threaded on cpu6 (Cortex-A76)

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - 64000000 - - - - - -

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:    435 MB,  # Benchmark threads:      1

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       2986   100   2906   2906  |      37305   100   3185   3185
23:       2846   100   2900   2900  |      36861   100   3191   3191
24:       2726   100   2932   2932  |      36205   100   3179   3178
25:       2606   100   2976   2976  |      35329   100   3145   3145
----------------------------------  | ------------------------------
Avr:             100   2928   2928  |              100   3175   3175
Tot:             100   3052   3052

##########################################################################

Executing benchmark 3 times multi-threaded

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - - - - - - - -

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:      12971   711   1775  12619  |     151102   655   1966  12888
23:      11624   731   1621  11844  |     141898   665   1847  12279
24:      11106   746   1600  11941  |     118434   664   1566  10395
25:      10352   774   1526  11820  |     109089   626   1551   9709
----------------------------------  | ------------------------------
Avr:             741   1631  12056  |              652   1733  11318
Tot:             696   1682  11687

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - - - - - - - -

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:      11525   734   1528  11212  |     112632   623   1543   9607
23:      10724   734   1490  10927  |     114293   654   1513   9891
24:      10709   754   1528  11515  |     108031   606   1566   9482
25:       9797   778   1437  11186  |     111685   671   1481   9940
----------------------------------  | ------------------------------
Avr:             750   1496  11210  |              638   1526   9730
Tot:             694   1511  10470

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - - - - - - - -

RAM size:    3740 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:      10424   762   1331  10141  |     119841   650   1574  10222
23:       9817   752   1330  10003  |     111413   659   1462   9641
24:       9342   737   1363  10046  |     108207   621   1530   9497
25:       7958   771   1179   9086  |     102269   602   1511   9102
----------------------------------  | ------------------------------
Avr:             756   1301   9819  |              633   1519   9616
Tot:             694   1410   9717

Compression: 12056,11210,9819
Decompression: 11318,9730,9616
Total: 11687,10470,9717

##########################################################################

** cpuminer-multi 1.3.3 by tpruvot@github **
BTC donation address: 1FhDPLPpw18X4srecguG3MxJYe4a1JsZnd (tpruvot)

[2022-05-16 08:00:35] 8 miner threads started, using 'scrypt' algorithm.
[2022-05-16 08:00:36] CPU #5: 2.66 kH/s
[2022-05-16 08:00:36] CPU #4: 2.64 kH/s
[2022-05-16 08:00:36] CPU #6: 2.63 kH/s
[2022-05-16 08:00:36] CPU #7: 2.55 kH/s
[2022-05-16 08:00:36] CPU #1: 0.83 kH/s
[2022-05-16 08:00:36] CPU #2: 0.83 kH/s
[2022-05-16 08:00:36] CPU #3: 0.83 kH/s
[2022-05-16 08:00:36] CPU #0: 0.73 kH/s
[2022-05-16 08:00:39] Total: 13.91 kH/s
[2022-05-16 08:00:40] Total: 14.41 kH/s
[2022-05-16 08:00:45] CPU #0: 0.80 kH/s
[2022-05-16 08:00:45] CPU #3: 0.81 kH/s
[2022-05-16 08:00:45] CPU #2: 0.81 kH/s
[2022-05-16 08:00:45] CPU #1: 0.81 kH/s
[2022-05-16 08:00:45] CPU #6: 2.80 kH/s
[2022-05-16 08:00:45] CPU #4: 2.85 kH/s
[2022-05-16 08:00:45] CPU #5: 2.86 kH/s
[2022-05-16 08:00:45] CPU #7: 2.72 kH/s
[2022-05-16 08:00:45] Total: 14.46 kH/s
[2022-05-16 08:00:51] CPU #7: 2.71 kH/s
[2022-05-16 08:00:51] Total: 14.38 kH/s
[2022-05-16 08:00:54] Total: 14.42 kH/s
[2022-05-16 08:00:55] CPU #0: 0.80 kH/s
[2022-05-16 08:00:55] CPU #1: 0.81 kH/s
[2022-05-16 08:00:55] CPU #2: 0.81 kH/s
[2022-05-16 08:00:55] CPU #3: 0.81 kH/s
[2022-05-16 08:00:55] CPU #6: 2.76 kH/s
[2022-05-16 08:00:55] CPU #4: 2.85 kH/s
[2022-05-16 08:00:55] CPU #5: 2.86 kH/s
[2022-05-16 08:00:55] Total: 14.50 kH/s
[2022-05-16 08:01:00] CPU #7: 2.80 kH/s
[2022-05-16 08:01:00] Total: 14.45 kH/s
[2022-05-16 08:01:05] CPU #0: 0.76 kH/s
[2022-05-16 08:01:05] CPU #1: 0.81 kH/s
[2022-05-16 08:01:05] CPU #2: 0.81 kH/s
[2022-05-16 08:01:05] CPU #3: 0.81 kH/s
[2022-05-16 08:01:05] CPU #6: 2.72 kH/s
[2022-05-16 08:01:05] CPU #4: 2.85 kH/s
[2022-05-16 08:01:05] CPU #5: 2.86 kH/s
[2022-05-16 08:01:05] Total: 14.43 kH/s
[2022-05-16 08:01:10] CPU #7: 2.80 kH/s
[2022-05-16 08:01:10] Total: 14.39 kH/s
[2022-05-16 08:01:15] CPU #0: 0.76 kH/s
[2022-05-16 08:01:15] CPU #2: 0.81 kH/s
[2022-05-16 08:01:15] CPU #1: 0.81 kH/s
[2022-05-16 08:01:15] CPU #3: 0.81 kH/s
[2022-05-16 08:01:15] CPU #6: 2.71 kH/s
[2022-05-16 08:01:15] CPU #4: 2.84 kH/s
[2022-05-16 08:01:15] CPU #5: 2.85 kH/s
[2022-05-16 08:01:15] Total: 14.41 kH/s
[2022-05-16 08:01:20] CPU #7: 2.77 kH/s
[2022-05-16 08:01:20] Total: 14.52 kH/s
[2022-05-16 08:01:25] CPU #0: 0.81 kH/s
[2022-05-16 08:01:25] CPU #2: 0.82 kH/s
[2022-05-16 08:01:25] CPU #1: 0.82 kH/s
[2022-05-16 08:01:25] CPU #3: 0.82 kH/s
[2022-05-16 08:01:25] CPU #6: 2.83 kH/s
[2022-05-16 08:01:25] CPU #4: 2.88 kH/s
[2022-05-16 08:01:25] CPU #5: 2.88 kH/s
[2022-05-16 08:01:26] CPU #7: 2.75 kH/s
[2022-05-16 08:01:26] Total: 14.60 kH/s
[2022-05-16 08:01:30] Total: 14.59 kH/s
[2022-05-16 08:01:35] CPU #7: 2.72 kH/s
[2022-05-16 08:01:35] Total: 14.60 kH/s
[2022-05-16 08:01:35] CPU #0: 0.82 kH/s
[2022-05-16 08:01:35] CPU #2: 0.82 kH/s
[2022-05-16 08:01:35] CPU #3: 0.82 kH/s
[2022-05-16 08:01:35] CPU #1: 0.82 kH/s
[2022-05-16 08:01:35] CPU #6: 2.84 kH/s
[2022-05-16 08:01:35] CPU #4: 2.89 kH/s
[2022-05-16 08:01:35] CPU #5: 2.90 kH/s
[2022-05-16 08:01:39] Total: 14.68 kH/s
[2022-05-16 08:01:40] Total: 14.64 kH/s
[2022-05-16 08:01:45] CPU #6: 2.85 kH/s
[2022-05-16 08:01:45] CPU #4: 2.92 kH/s
[2022-05-16 08:01:45] CPU #5: 2.94 kH/s
[2022-05-16 08:01:46] CPU #7: 2.80 kH/s
[2022-05-16 08:01:46] Total: 14.62 kH/s
[2022-05-16 08:01:46] CPU #0: 0.60 kH/s
[2022-05-16 08:01:46] CPU #2: 0.63 kH/s
[2022-05-16 08:01:46] CPU #3: 0.63 kH/s
[2022-05-16 08:01:46] CPU #1: 0.63 kH/s
[2022-05-16 08:01:50] Total: 14.02 kH/s
[2022-05-16 08:01:55] CPU #7: 2.81 kH/s
[2022-05-16 08:01:55] Total: 14.07 kH/s
[2022-05-16 08:01:55] CPU #6: 2.90 kH/s
[2022-05-16 08:01:55] CPU #4: 2.93 kH/s
[2022-05-16 08:01:55] CPU #5: 2.95 kH/s
[2022-05-16 08:01:55] CPU #2: 0.64 kH/s
[2022-05-16 08:01:55] CPU #1: 0.64 kH/s
[2022-05-16 08:01:55] CPU #3: 0.64 kH/s
[2022-05-16 08:01:55] CPU #0: 0.58 kH/s
[2022-05-16 08:01:59] Total: 14.14 kH/s
[2022-05-16 08:02:00] Total: 14.18 kH/s
[2022-05-16 08:02:05] CPU #0: 0.63 kH/s
[2022-05-16 08:02:05] CPU #6: 2.82 kH/s
[2022-05-16 08:02:05] CPU #4: 2.94 kH/s
[2022-05-16 08:02:05] CPU #5: 2.95 kH/s
[2022-05-16 08:02:05] CPU #2: 0.64 kH/s
[2022-05-16 08:02:05] CPU #3: 0.64 kH/s
[2022-05-16 08:02:05] CPU #1: 0.64 kH/s
[2022-05-16 08:02:06] CPU #7: 2.86 kH/s
[2022-05-16 08:02:06] Total: 14.12 kH/s
[2022-05-16 08:02:10] Total: 14.16 kH/s
[2022-05-16 08:02:15] CPU #7: 2.89 kH/s
[2022-05-16 08:02:15] Total: 14.16 kH/s
[2022-05-16 08:02:15] CPU #0: 0.63 kH/s
[2022-05-16 08:02:15] CPU #6: 2.81 kH/s
[2022-05-16 08:02:15] CPU #4: 2.92 kH/s
[2022-05-16 08:02:15] CPU #5: 2.94 kH/s
[2022-05-16 08:02:15] CPU #2: 0.63 kH/s
[2022-05-16 08:02:15] CPU #3: 0.63 kH/s
[2022-05-16 08:02:15] CPU #1: 0.64 kH/s
[2022-05-16 08:02:20] Total: 14.08 kH/s
[2022-05-16 08:02:25] CPU #7: 2.88 kH/s
[2022-05-16 08:02:25] Total: 14.05 kH/s
[2022-05-16 08:02:25] CPU #0: 0.63 kH/s
[2022-05-16 08:02:25] CPU #6: 2.81 kH/s
[2022-05-16 08:02:25] CPU #4: 2.93 kH/s
[2022-05-16 08:02:25] CPU #5: 2.95 kH/s
[2022-05-16 08:02:25] CPU #2: 0.64 kH/s
[2022-05-16 08:02:25] CPU #3: 0.64 kH/s
[2022-05-16 08:02:25] CPU #1: 0.64 kH/s
[2022-05-16 08:02:30] Total: 14.02 kH/s
[2022-05-16 08:02:35] CPU #7: 2.79 kH/s
[2022-05-16 08:02:35] Total: 14.04 kH/s
[2022-05-16 08:02:35] CPU #6: 2.88 kH/s
[2022-05-16 08:02:35] CPU #5: 2.93 kH/s
[2022-05-16 08:02:35] CPU #4: 2.91 kH/s
[2022-05-16 08:02:35] CPU #2: 0.63 kH/s
[2022-05-16 08:02:35] CPU #3: 0.63 kH/s
[2022-05-16 08:02:35] CPU #1: 0.63 kH/s
[2022-05-16 08:02:36] CPU #0: 0.57 kH/s
[2022-05-16 08:02:40] Total: 13.99 kH/s
[2022-05-16 08:02:44] CPU #0: 0.62 kH/s
[2022-05-16 08:02:45] CPU #7: 2.81 kH/s
[2022-05-16 08:02:45] Total: 14.09 kH/s
[2022-05-16 08:02:45] CPU #6: 2.89 kH/s
[2022-05-16 08:02:45] CPU #4: 2.92 kH/s
[2022-05-16 08:02:45] CPU #5: 2.94 kH/s
[2022-05-16 08:02:45] CPU #2: 0.63 kH/s
[2022-05-16 08:02:45] CPU #1: 0.64 kH/s
[2022-05-16 08:02:45] CPU #3: 0.63 kH/s
[2022-05-16 08:02:50] Total: 14.08 kH/s
[2022-05-16 08:02:50] CPU #0: 0.62 kH/s
[2022-05-16 08:02:55] CPU #7: 2.81 kH/s
[2022-05-16 08:02:55] Total: 14.04 kH/s
[2022-05-16 08:02:55] CPU #6: 2.88 kH/s
[2022-05-16 08:02:55] CPU #4: 2.94 kH/s
[2022-05-16 08:02:55] CPU #5: 2.94 kH/s
[2022-05-16 08:02:55] CPU #2: 0.64 kH/s
[2022-05-16 08:02:55] CPU #1: 0.64 kH/s
[2022-05-16 08:02:55] CPU #3: 0.64 kH/s
[2022-05-16 08:03:00] Total: 14.08 kH/s
[2022-05-16 08:03:00] CPU #0: 0.63 kH/s
[2022-05-16 08:03:05] CPU #7: 2.90 kH/s
[2022-05-16 08:03:05] Total: 14.19 kH/s
[2022-05-16 08:03:05] CPU #6: 2.83 kH/s
[2022-05-16 08:03:05] CPU #4: 2.94 kH/s
[2022-05-16 08:03:05] CPU #5: 2.95 kH/s
[2022-05-16 08:03:05] CPU #2: 0.64 kH/s
[2022-05-16 08:03:05] CPU #1: 0.64 kH/s
[2022-05-16 08:03:05] CPU #3: 0.64 kH/s
[2022-05-16 08:03:10] Total: 14.16 kH/s
[2022-05-16 08:03:10] CPU #0: 0.62 kH/s
[2022-05-16 08:03:15] CPU #7: 2.87 kH/s
[2022-05-16 08:03:15] Total: 14.05 kH/s
[2022-05-16 08:03:15] CPU #6: 2.88 kH/s
[2022-05-16 08:03:15] CPU #5: 2.93 kH/s
[2022-05-16 08:03:15] CPU #4: 2.84 kH/s
[2022-05-16 08:03:15] CPU #2: 0.63 kH/s
[2022-05-16 08:03:15] CPU #1: 0.63 kH/s
[2022-05-16 08:03:15] CPU #3: 0.63 kH/s
[2022-05-16 08:03:16] CPU #0: 0.57 kH/s
[2022-05-16 08:03:20] Total: 13.96 kH/s
[2022-05-16 08:03:21] CPU #1: 0.62 kH/s
[2022-05-16 08:03:21] CPU #3: 0.62 kH/s
[2022-05-16 08:03:24] CPU #0: 0.59 kH/s
[2022-05-16 08:03:25] CPU #7: 2.83 kH/s
[2022-05-16 08:03:25] Total: 13.94 kH/s
[2022-05-16 08:03:25] CPU #6: 2.85 kH/s
[2022-05-16 08:03:25] CPU #5: 2.94 kH/s
[2022-05-16 08:03:25] CPU #4: 2.92 kH/s
[2022-05-16 08:03:25] CPU #2: 0.64 kH/s
[2022-05-16 08:03:30] Total: 14.09 kH/s
[2022-05-16 08:03:30] CPU #0: 0.62 kH/s
[2022-05-16 08:03:31] CPU #3: 0.63 kH/s
[2022-05-16 08:03:31] CPU #1: 0.63 kH/s
[2022-05-16 08:03:35] CPU #7: 2.82 kH/s
[2022-05-16 08:03:35] Total: 14.04 kH/s
[2022-05-16 08:03:35] CPU #6: 2.85 kH/s
[2022-05-16 08:03:35] CPU #4: 2.93 kH/s
[2022-05-16 08:03:35] CPU #5: 2.94 kH/s
[2022-05-16 08:03:35] CPU #2: 0.64 kH/s
[2022-05-16 08:03:40] Total: 14.10 kH/s
[2022-05-16 08:03:40] CPU #0: 0.63 kH/s
[2022-05-16 08:03:40] CPU #3: 0.63 kH/s
[2022-05-16 08:03:40] CPU #1: 0.64 kH/s
[2022-05-16 08:03:45] CPU #7: 2.89 kH/s
[2022-05-16 08:03:45] Total: 14.13 kH/s
[2022-05-16 08:03:45] CPU #6: 2.77 kH/s
[2022-05-16 08:03:45] CPU #5: 2.94 kH/s
[2022-05-16 08:03:45] CPU #4: 2.93 kH/s
[2022-05-16 08:03:45] CPU #2: 0.63 kH/s
[2022-05-16 08:03:50] Total: 14.06 kH/s
[2022-05-16 08:03:50] CPU #0: 0.62 kH/s
[2022-05-16 08:03:50] CPU #3: 0.63 kH/s
[2022-05-16 08:03:50] CPU #1: 0.63 kH/s
[2022-05-16 08:03:55] CPU #7: 2.88 kH/s
[2022-05-16 08:03:55] Total: 14.07 kH/s
[2022-05-16 08:03:55] CPU #6: 2.84 kH/s
[2022-05-16 08:03:55] CPU #5: 2.93 kH/s
[2022-05-16 08:03:55] CPU #4: 2.87 kH/s
[2022-05-16 08:03:55] CPU #2: 0.63 kH/s
[2022-05-16 08:03:56] CPU #0: 0.59 kH/s
[2022-05-16 08:04:00] Total: 13.98 kH/s
[2022-05-16 08:04:01] CPU #3: 0.62 kH/s
[2022-05-16 08:04:01] CPU #1: 0.62 kH/s
[2022-05-16 08:04:05] CPU #7: 2.88 kH/s
[2022-05-16 08:04:05] Total: 13.93 kH/s
[2022-05-16 08:04:05] CPU #0: 0.58 kH/s
[2022-05-16 08:04:05] CPU #6: 2.89 kH/s
[2022-05-16 08:04:05] CPU #5: 2.94 kH/s
[2022-05-16 08:04:05] CPU #4: 2.83 kH/s
[2022-05-16 08:04:05] CPU #2: 0.63 kH/s
[2022-05-16 08:04:10] Total: 14.01 kH/s
[2022-05-16 08:04:10] CPU #3: 0.64 kH/s
[2022-05-16 08:04:10] CPU #1: 0.64 kH/s
[2022-05-16 08:04:15] CPU #7: 2.89 kH/s
[2022-05-16 08:04:15] Total: 14.15 kH/s
[2022-05-16 08:04:15] CPU #6: 2.82 kH/s
[2022-05-16 08:04:15] CPU #5: 2.95 kH/s
[2022-05-16 08:04:15] CPU #4: 2.93 kH/s
[2022-05-16 08:04:15] CPU #2: 0.64 kH/s
[2022-05-16 08:04:15] CPU #0: 0.63 kH/s
[2022-05-16 08:04:20] Total: 14.13 kH/s
[2022-05-16 08:04:20] CPU #3: 0.64 kH/s
[2022-05-16 08:04:20] CPU #1: 0.64 kH/s
[2022-05-16 08:04:25] CPU #7: 2.89 kH/s
[2022-05-16 08:04:25] Total: 14.06 kH/s
[2022-05-16 08:04:25] CPU #6: 2.81 kH/s
[2022-05-16 08:04:25] CPU #5: 2.95 kH/s
[2022-05-16 08:04:25] CPU #4: 2.93 kH/s
[2022-05-16 08:04:25] CPU #2: 0.64 kH/s
[2022-05-16 08:04:25] CPU #0: 0.63 kH/s
[2022-05-16 08:04:30] Total: 14.10 kH/s
[2022-05-16 08:04:30] CPU #3: 0.64 kH/s
[2022-05-16 08:04:30] CPU #1: 0.64 kH/s
[2022-05-16 08:04:35] CPU #7: 2.81 kH/s
[2022-05-16 08:04:35] Total: 14.09 kH/s
[2022-05-16 08:04:35] CPU #6: 2.89 kH/s
[2022-05-16 08:04:35] CPU #5: 2.94 kH/s
[2022-05-16 08:04:35] CPU #4: 2.92 kH/s
[2022-05-16 08:04:35] CPU #2: 0.63 kH/s
[2022-05-16 08:04:36] CPU #0: 0.62 kH/s
[2022-05-16 08:04:40] Total: 14.07 kH/s
[2022-05-16 08:04:40] CPU #3: 0.64 kH/s
[2022-05-16 08:04:40] CPU #1: 0.64 kH/s
[2022-05-16 08:04:45] CPU #7: 2.82 kH/s
[2022-05-16 08:04:45] Total: 14.15 kH/s
[2022-05-16 08:04:45] CPU #6: 2.89 kH/s
[2022-05-16 08:04:45] CPU #5: 2.95 kH/s
[2022-05-16 08:04:45] CPU #4: 2.93 kH/s
[2022-05-16 08:04:45] CPU #2: 0.64 kH/s
[2022-05-16 08:04:46] CPU #0: 0.63 kH/s
[2022-05-16 08:04:50] Total: 14.20 kH/s
[2022-05-16 08:04:50] CPU #3: 0.64 kH/s
[2022-05-16 08:04:50] CPU #1: 0.64 kH/s
[2022-05-16 08:04:55] CPU #7: 2.88 kH/s
[2022-05-16 08:04:55] Total: 14.09 kH/s
[2022-05-16 08:04:55] CPU #0: 0.62 kH/s
[2022-05-16 08:04:55] CPU #6: 2.80 kH/s
[2022-05-16 08:04:55] CPU #4: 2.92 kH/s
[2022-05-16 08:04:55] CPU #5: 2.93 kH/s
[2022-05-16 08:04:55] CPU #2: 0.63 kH/s
[2022-05-16 08:05:00] Total: 13.97 kH/s
[2022-05-16 08:05:00] CPU #3: 0.64 kH/s
[2022-05-16 08:05:00] CPU #1: 0.64 kH/s
[2022-05-16 08:05:05] CPU #0: 0.62 kH/s
[2022-05-16 08:05:05] CPU #7: 2.84 kH/s
[2022-05-16 08:05:05] Total: 14.10 kH/s
[2022-05-16 08:05:05] CPU #6: 2.84 kH/s
[2022-05-16 08:05:05] CPU #4: 2.92 kH/s
[2022-05-16 08:05:05] CPU #5: 2.93 kH/s
[2022-05-16 08:05:05] CPU #2: 0.63 kH/s
[2022-05-16 08:05:10] Total: 14.09 kH/s
[2022-05-16 08:05:10] CPU #3: 0.63 kH/s
[2022-05-16 08:05:10] CPU #1: 0.63 kH/s
[2022-05-16 08:05:15] CPU #7: 2.87 kH/s
[2022-05-16 08:05:15] Total: 13.99 kH/s
[2022-05-16 08:05:15] CPU #0: 0.57 kH/s
[2022-05-16 08:05:15] CPU #6: 2.88 kH/s
[2022-05-16 08:05:15] CPU #5: 2.93 kH/s
[2022-05-16 08:05:15] CPU #2: 0.63 kH/s
[2022-05-16 08:05:15] CPU #4: 2.82 kH/s
[2022-05-16 08:05:20] Total: 13.94 kH/s
[2022-05-16 08:05:20] CPU #1: 0.63 kH/s
[2022-05-16 08:05:20] CPU #3: 0.63 kH/s
[2022-05-16 08:05:25] CPU #0: 0.63 kH/s
[2022-05-16 08:05:25] CPU #7: 2.88 kH/s
[2022-05-16 08:05:25] Total: 14.01 kH/s
[2022-05-16 08:05:25] CPU #6: 2.81 kH/s
[2022-05-16 08:05:25] CPU #5: 2.95 kH/s
[2022-05-16 08:05:25] CPU #4: 2.93 kH/s
[2022-05-16 08:05:25] CPU #2: 0.64 kH/s
[2022-05-16 08:05:30] Total: 14.03 kH/s
[2022-05-16 08:05:30] CPU #1: 0.63 kH/s
[2022-05-16 08:05:30] CPU #3: 0.63 kH/s
[2022-05-16 08:05:35] CPU #0: 0.62 kH/s
[2022-05-16 08:05:35] CPU #7: 2.77 kH/s
[2022-05-16 08:05:35] Total: 14.05 kH/s
[2022-05-16 08:05:35] CPU #6: 2.88 kH/s
[2022-05-16 08:05:35] CPU #5: 2.94 kH/s
[2022-05-16 08:05:35] CPU #4: 2.93 kH/s
[2022-05-16 08:05:35] CPU #2: 0.64 kH/s

Total Scores: 14.68,14.64,14.62,14.60,14.59,14.52,14.50,14.46,14.45,14.43,14.42,14.41,14.39,14.38,14.20,14.19,14.18,14.16,14.15,14.14,14.13,14.12,14.10,14.09,14.08,14.07,14.06,14.05,14.04,14.03,14.02,14.01,13.99,13.98,13.97,13.96,13.94,13.93,13.91

##########################################################################

Testing clockspeeds again. System health now:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
08:05:04: 1608/ 600MHz  8.45 100%   0%  99%   0%   0%   0%  84.1Â°C

Checking cpufreq OPP for cpu0-cpu3 (Cortex-A55):

Cpufreq OPP: 1800    Measured: 1315 (1314.380/1256.665/740.901)
Cpufreq OPP: 1608    Measured: 1290 (1285.258/1282.017/1026.076)
Cpufreq OPP: 1416    Measured: 1615 (1614.998/1323.836/1319.081)
Cpufreq OPP: 1200    Measured:  990 (988.035/981.958/964.547)
Cpufreq OPP: 1008    Measured:  945 (943.062/928.817/896.523)
Cpufreq OPP:  816    Measured:  800 (795.950/790.261/484.054)
Cpufreq OPP:  600    Measured:  620 (618.204/459.044/391.036)
Cpufreq OPP:  408    Measured:  395 (391.388/390.688/386.937)

Checking cpufreq OPP for cpu4-cpu5 (Cortex-A76):

Cpufreq OPP: 2400    Measured:  780 (775.340/745.686/718.466)
Cpufreq OPP: 2208    Measured: 1200 (1198.870/1003.185/705.800)
Cpufreq OPP: 2016    Measured: 1265 (1261.292/864.451/758.835)
Cpufreq OPP: 1800    Measured: 1070 (1066.585/915.515/831.915)
Cpufreq OPP: 1608    Measured: 1480 (1478.597/721.498/682.952)
Cpufreq OPP: 1416    Measured: 1200 (1199.348/1094.915/683.096)
Cpufreq OPP: 1200    Measured: 1205 (1200.880/1053.873/764.504)
Cpufreq OPP: 1008    Measured:  980 (979.648/468.917/292.616)
Cpufreq OPP:  816    Measured: 1055 (1050.289/789.569/789.201)
Cpufreq OPP:  600    Measured:  595 (592.884/592.798/592.459)
Cpufreq OPP:  408    Measured:  395 (394.936/394.900/394.522)

Checking cpufreq OPP for cpu6-cpu7 (Cortex-A76):

Cpufreq OPP: 2400    Measured: 1980 (1979.643/1979.526/1945.418)
Cpufreq OPP: 2208    Measured: 2120 (2117.027/2019.753/1989.947)
Cpufreq OPP: 2016    Measured: 1930 (1928.027/1841.368/1827.731)
Cpufreq OPP: 1800    Measured: 1775 (1773.860/1773.606/1773.217)
Cpufreq OPP: 1608    Measured: 1460 (1458.685/1442.955/1433.074)
Cpufreq OPP: 1416    Measured: 1400 (1395.970/1377.519/1348.193)
Cpufreq OPP: 1200    Measured: 1295 (1292.144/1152.382/1044.816)
Cpufreq OPP: 1008    Measured:  640 (637.286/627.494/594.877)
Cpufreq OPP:  816    Measured:  640 (636.653/636.270/629.627)
Cpufreq OPP:  600    Measured:  470 (465.298/439.137/405.205)
Cpufreq OPP:  408    Measured:  395 (394.987/394.955/394.881)

##########################################################################

Hardware sensors:

npu_thermal-virtual-0
temp1:        +82.2 C  

center_thermal-virtual-0
temp1:        +83.2 C  

bigcore1_thermal-virtual-0
temp1:        +85.0 C  

soc_thermal-virtual-0
temp1:        +84.1 C  (crit = +115.0 C)

gpu_thermal-virtual-0
temp1:        +82.2 C  

littlecore_thermal-virtual-0
temp1:        +84.1 C  

bigcore0_thermal-virtual-0
temp1:        +85.0 C  

##########################################################################

Thermal source: /sys/devices/virtual/thermal/thermal_zone0/ (soc-thermal)

System health while running tinymembench:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
07:32:35: 2400/1800MHz  1.14   1%   0%   0%   0%   0%   0%  64.7Â°C
07:34:35: 2400/1800MHz  1.14  12%   0%  12%   0%   0%   0%  80.4Â°C
07:36:35: 2400/1800MHz  1.15  12%   0%  12%   0%   0%   0%  73.9Â°C
07:38:35: 2400/1800MHz  1.02  12%   0%  12%   0%   0%   0%  70.2Â°C
07:40:35: 2400/1608MHz  1.30  13%   0%  12%   0%   0%   0%  83.2Â°C
07:42:35: 2400/1800MHz  1.17  13%   0%  12%   0%   0%   0%  77.6Â°C
07:44:35: 2400/ 816MHz  1.11  13%   0%  12%   0%   0%   0%  84.1Â°C
07:46:35: 2400/ 408MHz  1.51  13%   0%  12%   0%   0%   0%  85.0Â°C
07:48:35: 2400/1800MHz  1.18  13%   0%  12%   0%   0%   0%  78.5Â°C

System health while running ramlat:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
07:49:35: 2400/1800MHz  1.21   1%   0%   0%   0%   0%   0%  78.5Â°C
07:49:44: 2400/1800MHz  1.32  12%   0%  12%   0%   0%   0%  75.8Â°C
07:49:53: 2400/1800MHz  1.27  12%   0%  12%   0%   0%   0%  75.8Â°C
07:50:03: 2400/1800MHz  1.30  12%   0%  12%   0%   0%   0%  75.8Â°C
07:50:12: 2400/1800MHz  1.26  12%   0%  12%   0%   0%   0%  76.7Â°C
07:50:21: 2400/1800MHz  1.22  12%   0%  12%   0%   0%   0%  77.6Â°C
07:50:30: 2400/1800MHz  1.20  13%   0%  12%   0%   0%   0%  76.7Â°C
07:50:39: 2400/1800MHz  1.17  12%   0%  12%   0%   0%   0%  77.6Â°C

System health while running OpenSSL benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
07:50:42: 2400/1800MHz  1.15   1%   0%   0%   0%   0%   0%  78.5Â°C
07:50:58: 2400/1800MHz  1.12  12%   0%  12%   0%   0%   0%  73.9Â°C
07:51:14: 2400/1800MHz  1.09  12%   0%  12%   0%   0%   0%  75.8Â°C
07:51:30: 2400/1800MHz  1.07  12%   0%  12%   0%   0%   0%  75.8Â°C
07:51:46: 2400/1800MHz  1.05  12%   0%  12%   0%   0%   0%  73.9Â°C
07:52:02: 2400/1800MHz  1.11  12%   0%  12%   0%   0%   0%  75.8Â°C
07:52:18: 2400/1800MHz  1.08  13%   0%  12%   0%   0%   0%  77.6Â°C
07:52:34: 2400/1800MHz  1.14  13%   0%  12%   0%   0%   0%  73.9Â°C
07:52:50: 2400/1800MHz  1.11  12%   0%  12%   0%   0%   0%  75.8Â°C
07:53:06: 2400/1800MHz  1.08  12%   0%  12%   0%   0%   0%  75.8Â°C
07:53:22: 2400/1800MHz  1.13  12%   0%  12%   0%   0%   0%  75.8Â°C

System health while running 7-zip single core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
07:53:24: 2400/1800MHz  1.13   1%   0%   0%   0%   0%   0%  76.7Â°C
07:53:35: 2400/1800MHz  1.11  12%   0%  12%   0%   0%   0%  73.0Â°C
07:53:46: 2400/1800MHz  1.09  12%   0%  12%   0%   0%   0%  73.0Â°C
07:53:57: 2400/1800MHz  1.23  12%   0%  12%   0%   0%   0%  73.0Â°C
07:54:08: 2400/1800MHz  1.19  12%   0%  11%   0%   0%   0%  72.1Â°C
07:54:19: 2400/1800MHz  1.16  12%   0%  12%   0%   0%   0%  72.1Â°C
07:54:30: 2400/1800MHz  1.14  12%   0%  12%   0%   0%   0%  72.1Â°C
07:54:41: 2400/1800MHz  1.19  12%   0%  11%   0%   0%   0%  73.0Â°C
07:54:52: 2400/1800MHz  1.16  12%   0%  11%   0%   0%   0%  72.1Â°C
07:55:03: 2400/1800MHz  1.13  12%   0%  12%   0%   0%   0%  74.8Â°C
07:55:14: 2400/1800MHz  1.11  12%   0%  12%   0%   0%   0%  75.8Â°C
07:55:25: 2400/1800MHz  1.09  13%   0%  12%   0%   0%   0%  76.7Â°C
07:55:36: 2400/1800MHz  1.07  13%   0%  12%   0%   0%   0%  76.7Â°C
07:55:47: 2400/1800MHz  1.06  12%   0%  12%   0%   0%   0%  76.7Â°C
07:55:58: 2400/1800MHz  1.13  13%   0%  12%   0%   0%   0%  77.6Â°C
07:56:09: 2400/1800MHz  1.19  13%   0%  12%   0%   0%   0%  78.5Â°C
07:56:20: 2400/1800MHz  1.16  13%   0%  12%   0%   0%   0%  78.5Â°C
07:56:32: 2400/1800MHz  1.12  13%   0%  12%   0%   0%   0%  78.5Â°C

System health while running 7-zip multi core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
07:56:33: 2400/1800MHz  1.12   1%   0%   0%   0%   0%   0%  79.5Â°C
07:56:43: 1608/1200MHz  2.33  95%   0%  94%   0%   0%   0%  85.0Â°C
07:56:54: 1608/1200MHz  2.91  79%   1%  76%   0%   0%   1%  85.0Â°C
07:57:04: 1608/1200MHz  3.37  77%   1%  76%   0%   0%   0%  85.0Â°C
07:57:14:  408/1200MHz  4.08  96%   1%  95%   0%   0%   0%  85.0Â°C
07:57:25: 1416/1200MHz  4.05  71%   1%  68%   0%   0%   0%  85.0Â°C
07:57:35: 1800/1200MHz  4.96  97%   2%  93%   0%   0%   0%  85.0Â°C
07:57:45: 2016/1200MHz  5.27  79%   0%  78%   0%   0%   0%  84.1Â°C
07:57:57:  408/1008MHz  5.48  91%   0%  90%   0%   0%   0%  85.0Â°C
07:58:07: 1416/1200MHz  5.88  69%   1%  67%   0%   0%   0%  85.0Â°C
07:58:17: 1800/1200MHz  6.13  92%   1%  89%   0%   0%   1%  84.1Â°C
07:58:28: 1416/1200MHz  6.12  78%   1%  75%   0%   0%   0%  85.0Â°C
07:58:38: 1608/ 600MHz  6.25  88%   0%  86%   0%   0%   0%  85.0Â°C
07:58:48: 1200/ 816MHz  6.30  70%   2%  67%   0%   0%   0%  85.0Â°C
07:59:03: 1200/ 816MHz  6.87  98%   2%  94%   0%   0%   0%  85.0Â°C
07:59:13: 2400/1800MHz  7.04  83%   1%  82%   0%   0%   0%  84.1Â°C
07:59:23: 1608/ 408MHz  7.51  94%   0%  93%   0%   0%   0%  84.1Â°C
07:59:34: 1416/1416MHz  7.14  79%   1%  77%   0%   0%   0%  85.0Â°C
07:59:44: 2400/1800MHz  7.19  79%   0%  77%   0%   0%   1%  84.1Â°C
07:59:58: 1608/ 408MHz  7.31  89%   2%  87%   0%   0%   0%  84.1Â°C
08:00:09: 1416/ 408MHz  6.67  72%   1%  71%   0%   0%   0%  84.1Â°C
08:00:19: 1416/ 408MHz  7.11  99%   3%  95%   0%   0%   0%  85.0Â°C
08:00:30: 1608/ 408MHz  7.40  97%   3%  91%   0%   0%   1%  84.1Â°C

System health while running cpuminer:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
08:00:35: 2400/1800MHz  7.12   1%   0%   0%   0%   0%   0%  85.0Â°C
08:01:21: 1608/ 816MHz  7.81 100%   0%  99%   0%   0%   0%  84.1Â°C
08:02:05: 1608/ 600MHz  8.03 100%   0%  99%   0%   0%   0%  84.1Â°C
08:02:50: 1608/ 600MHz  8.17 100%   0%  99%   0%   0%   0%  84.1Â°C
08:03:34: 1608/ 600MHz  8.38 100%   0%  99%   0%   0%   0%  83.2Â°C
08:04:19: 1608/ 600MHz  8.53 100%   0%  99%   0%   0%   0%  83.2Â°C
08:05:04: 1608/ 600MHz  8.45 100%   0%  99%   0%   0%   0%  84.1Â°C

##########################################################################

Throttling statistics (time spent on each cpufreq OPP) for CPUs 0-3 (Cortex-A55):

1800 MHz: 1175.51 sec
1608 MHz:    7.73 sec
1416 MHz:   23.26 sec
1200 MHz:   95.11 sec
1008 MHz:   31.97 sec
 816 MHz:  117.35 sec
 600 MHz:  235.46 sec
 408 MHz:  294.30 sec

Throttling statistics (time spent on each cpufreq OPP) for CPUs 4-5 (Cortex-A76):

2400 MHz: 1270.39 sec
2208 MHz:    2.96 sec
2016 MHz:   16.47 sec
1800 MHz:   60.67 sec
1608 MHz:  335.04 sec
1416 MHz:   56.88 sec
1200 MHz:   16.76 sec
1008 MHz:    7.38 sec
 816 MHz:    0.33 sec
 600 MHz:    8.54 sec
 408 MHz:  205.30 sec

Throttling statistics (time spent on each cpufreq OPP) for CPUs 6-7 (Cortex-A76):

2400 MHz: 1336.60 sec
2208 MHz:    2.81 sec
2016 MHz:   10.53 sec
1800 MHz:   60.84 sec
1608 MHz:  355.43 sec
1416 MHz:   63.00 sec
1200 MHz:   16.39 sec
1008 MHz:    1.35 sec
 816 MHz:    0.24 sec
 600 MHz:    4.91 sec
 408 MHz:  128.58 sec

##########################################################################

dmesg output while running the benchmarks:

[251074.046545] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[251081.083111] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[251354.356011] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251398.520641] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251398.622412] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[251405.579504] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251442.663939] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251442.765193] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[251449.908841] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251450.011810] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[251487.055976] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[251494.051198] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[252277.424069] PHL: ERROR _cmd_swch_done_notify: [SWCH_DONE] phl_disp_eng_send_msg failed!
[252277.434247] PHL: ERROR phl_cmd_enqueue send msg failed
[252277.525408] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[252284.748610] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !
[252609.584735] PHL: ERROR _cmd_scan_timer: [SCAN_TIMER] phl_disp_eng_send_msg failed !

##########################################################################

Linux 5.10.66-rockchip-5.10 (radxa) 	05/16/22 	_aarch64_	(8 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.33    0.00    0.98    0.01    0.00   98.68

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
mmcblk0           0.61         0.68         7.95       118.27     170841    2008794   29877055

               total        used        free      shared  buff/cache   available
Mem:           3.7Gi       252Mi       3.3Gi       9.0Mi       118Mi       3.4Gi
Swap:             0B          0B          0B

CPU sysfs topology (clusters, cpufreq members, clockspeeds)
                 cpufreq   min    max
 CPU    cluster  policy   speed  speed   core type
  0        0        0      408    1800   Cortex-A55 / r2p0
  1        0        0      408    1800   Cortex-A55 / r2p0
  2        0        0      408    1800   Cortex-A55 / r2p0
  3        0        0      408    1800   Cortex-A55 / r2p0
  4        1        4      408    2400   Cortex-A76 / r4p0
  5        1        4      408    2400   Cortex-A76 / r4p0
  6        2        6      408    2400   Cortex-A76 / r4p0
  7        2        6      408    2400   Cortex-A76 / r4p0

Architecture:                    aarch64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
CPU(s):                          8
On-line CPU(s) list:             0-7
Thread(s) per core:              1
Core(s) per socket:              2
Socket(s):                       3
Vendor ID:                       ARM
Model:                           0
Model name:                      Cortex-A55
Stepping:                        r2p0
CPU max MHz:                     2400.0000
CPU min MHz:                     408.0000
BogoMIPS:                        48.00
L1d cache:                       256 KiB
L1i cache:                       256 KiB
L2 cache:                        1 MiB
L3 cache:                        3 MiB
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:        Mitigation; __user pointer sanitization
Vulnerability Spectre v2:        Not affected
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp

SoC guess: Rockchip RK3588/RK3588s
DT compat: radxa,rock-5a
           rockchip,rk3588
 Compiler: /usr/bin/gcc (Debian 10.2.1-6/aarch64-linux-gnu)
 Userland: arm64
   Kernel: 5.10.66-rockchip-5.10/aarch64
           CONFIG_HZ=300
           CONFIG_HZ_300=y
           CONFIG_PREEMPT_VOLUNTARY=y

cpu0/index2: 128K, level: 2, type: Unified
cpu0/index0: 32K, level: 1, type: Data
cpu0/index3: 3072K, level: 3, type: Unified
cpu0/index1: 32K, level: 1, type: Instruction
cpu1/index2: 128K, level: 2, type: Unified
cpu1/index0: 32K, level: 1, type: Data
cpu1/index3: 3072K, level: 3, type: Unified
cpu1/index1: 32K, level: 1, type: Instruction
cpu2/index2: 128K, level: 2, type: Unified
cpu2/index0: 32K, level: 1, type: Data
cpu2/index3: 3072K, level: 3, type: Unified
cpu2/index1: 32K, level: 1, type: Instruction
cpu3/index2: 128K, level: 2, type: Unified
cpu3/index0: 32K, level: 1, type: Data
cpu3/index3: 3072K, level: 3, type: Unified
cpu3/index1: 32K, level: 1, type: Instruction
cpu4/index2: 512K, level: 2, type: Unified
cpu4/index0: 64K, level: 1, type: Data
cpu4/index3: 3072K, level: 3, type: Unified
cpu4/index1: 64K, level: 1, type: Instruction
cpu5/index2: 512K, level: 2, type: Unified
cpu5/index0: 64K, level: 1, type: Data
cpu5/index3: 3072K, level: 3, type: Unified
cpu5/index1: 64K, level: 1, type: Instruction
cpu6/index2: 512K, level: 2, type: Unified
cpu6/index0: 64K, level: 1, type: Data
cpu6/index3: 3072K, level: 3, type: Unified
cpu6/index1: 64K, level: 1, type: Instruction
cpu7/index2: 512K, level: 2, type: Unified
cpu7/index0: 64K, level: 1, type: Data
cpu7/index3: 3072K, level: 3, type: Unified
cpu7/index1: 64K, level: 1, type: Instruction

| Radxa ROCK 5A | 2400/2400 MHz | 5.10 | Bullseye arm64 | 10620 | 632100 | 1294730 | 7660 | 21300 | 14.64 |